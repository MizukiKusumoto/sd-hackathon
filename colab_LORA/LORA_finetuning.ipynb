{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i4GbmQnpLkU-"
      },
      "outputs": [],
      "source": [
        "#colab環境上でのLORA実行\n",
        "\n",
        "\n",
        "!cp -r /content/drive/MyDrive/trains ."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hh18fuCHs2-m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/kohya-ss/sd-scripts.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYQLYQGGMGXb",
        "outputId": "40a7b7dc-1d1a-4e8e-ebfd-167fd9853a9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'sd-scripts'...\n",
            "remote: Enumerating objects: 8334, done.\u001b[K\n",
            "remote: Counting objects: 100% (240/240), done.\u001b[K\n",
            "remote: Compressing objects: 100% (113/113), done.\u001b[K\n",
            "remote: Total 8334 (delta 154), reused 186 (delta 126), pack-reused 8094 (from 1)\u001b[K\n",
            "Receiving objects: 100% (8334/8334), 11.00 MiB | 6.27 MiB/s, done.\n",
            "Resolving deltas: 100% (6010/6010), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd sd-scripts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UafgX2O1MjLs",
        "outputId": "926c6a3f-0797-4438-f921-08e4aba9fe7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sd-scripts\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==2.1.2 torchvision==0.16.2 torchaudio==2.1.2 --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip install -U -r requirements.txt\n",
        "!pip install xformers==0.0.23.post1 --index-url https://download.pytorch.org/whl/cu121"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOD6Jn6AMtnP",
        "outputId": "da8214e7-c38e-4b32-a38d-231626cf292c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Collecting torch==2.1.2\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torch-2.1.2%2Bcu121-cp310-cp310-linux_x86_64.whl (2200.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 GB\u001b[0m \u001b[31m749.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.16.2\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.16.2%2Bcu121-cp310-cp310-linux_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m97.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==2.1.2\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.1.2%2Bcu121-cp310-cp310-linux_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m92.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2) (2024.10.0)\n",
            "Collecting triton==2.1.0 (from torch==2.1.2)\n",
            "  Downloading https://download.pytorch.org/whl/triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.16.2) (1.26.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.16.2) (2.32.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.16.2) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.2) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16.2) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16.2) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16.2) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.2) (1.3.0)\n",
            "Installing collected packages: triton, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu121\n",
            "    Uninstalling torch-2.5.1+cu121:\n",
            "      Successfully uninstalled torch-2.5.1+cu121\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.20.1+cu121\n",
            "    Uninstalling torchvision-0.20.1+cu121:\n",
            "      Successfully uninstalled torchvision-0.20.1+cu121\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.5.1+cu121\n",
            "    Uninstalling torchaudio-2.5.1+cu121:\n",
            "      Successfully uninstalled torchaudio-2.5.1+cu121\n",
            "Successfully installed torch-2.1.2+cu121 torchaudio-2.1.2+cu121 torchvision-0.16.2+cu121 triton-2.1.0\n",
            "Obtaining file:///content/sd-scripts (from -r requirements.txt (line 42))\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting accelerate==0.25.0 (from -r requirements.txt (line 1))\n",
            "  Downloading accelerate-0.25.0-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting transformers==4.36.2 (from -r requirements.txt (line 2))\n",
            "  Downloading transformers-4.36.2-py3-none-any.whl.metadata (126 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.8/126.8 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting diffusers==0.25.0 (from diffusers[torch]==0.25.0->-r requirements.txt (line 3))\n",
            "  Downloading diffusers-0.25.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting ftfy==6.1.1 (from -r requirements.txt (line 4))\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting opencv-python==4.8.1.78 (from -r requirements.txt (line 6))\n",
            "  Downloading opencv_python-4.8.1.78-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Collecting einops==0.7.0 (from -r requirements.txt (line 7))\n",
            "  Downloading einops-0.7.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting pytorch-lightning==1.9.0 (from -r requirements.txt (line 8))\n",
            "  Downloading pytorch_lightning-1.9.0-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting bitsandbytes==0.43.0 (from -r requirements.txt (line 9))\n",
            "  Downloading bitsandbytes-0.43.0-py3-none-manylinux_2_24_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting prodigyopt==1.0 (from -r requirements.txt (line 10))\n",
            "  Downloading prodigyopt-1.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting lion-pytorch==0.0.6 (from -r requirements.txt (line 11))\n",
            "  Downloading lion_pytorch-0.0.6-py3-none-any.whl.metadata (620 bytes)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (2.17.1)\n",
            "Collecting tensorboard (from -r requirements.txt (line 12))\n",
            "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting safetensors==0.4.2 (from -r requirements.txt (line 13))\n",
            "  Downloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: altair==4.2.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (4.2.2)\n",
            "Collecting easygui==0.98.3 (from -r requirements.txt (line 16))\n",
            "  Downloading easygui-0.98.3-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: toml==0.10.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (0.10.2)\n",
            "Collecting voluptuous==0.13.1 (from -r requirements.txt (line 18))\n",
            "  Downloading voluptuous-0.13.1-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting huggingface-hub==0.20.1 (from -r requirements.txt (line 19))\n",
            "  Downloading huggingface_hub-0.20.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: imagesize==1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 21)) (1.4.1)\n",
            "Collecting rich==13.7.0 (from -r requirements.txt (line 40))\n",
            "  Downloading rich-13.7.0-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.25.0->-r requirements.txt (line 1)) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.25.0->-r requirements.txt (line 1)) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.25.0->-r requirements.txt (line 1)) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.25.0->-r requirements.txt (line 1)) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.25.0->-r requirements.txt (line 1)) (2.1.2+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.2->-r requirements.txt (line 2)) (3.16.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.2->-r requirements.txt (line 2)) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.2->-r requirements.txt (line 2)) (2.32.3)\n",
            "Collecting tokenizers<0.19,>=0.14 (from transformers==4.36.2->-r requirements.txt (line 2))\n",
            "  Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.2->-r requirements.txt (line 2)) (4.66.6)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers==0.25.0->diffusers[torch]==0.25.0->-r requirements.txt (line 3)) (8.5.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers==0.25.0->diffusers[torch]==0.25.0->-r requirements.txt (line 3)) (11.0.0)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy==6.1.1->-r requirements.txt (line 4)) (0.2.13)\n",
            "Requirement already satisfied: fsspec>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning==1.9.0->-r requirements.txt (line 8)) (2024.10.0)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch-lightning==1.9.0->-r requirements.txt (line 8))\n",
            "  Downloading torchmetrics-1.6.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.9.0->-r requirements.txt (line 8)) (4.12.2)\n",
            "Collecting lightning-utilities>=0.4.2 (from pytorch-lightning==1.9.0->-r requirements.txt (line 8))\n",
            "  Downloading lightning_utilities-0.11.9-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair==4.2.2->-r requirements.txt (line 15)) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair==4.2.2->-r requirements.txt (line 15)) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair==4.2.2->-r requirements.txt (line 15)) (4.23.0)\n",
            "Requirement already satisfied: pandas>=0.18 in /usr/local/lib/python3.10/dist-packages (from altair==4.2.2->-r requirements.txt (line 15)) (2.2.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair==4.2.2->-r requirements.txt (line 15)) (0.12.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich==13.7.0->-r requirements.txt (line 40)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich==13.7.0->-r requirements.txt (line 40)) (2.18.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 12)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 12)) (1.68.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 12)) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 12)) (4.25.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 12)) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 12)) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 12)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 12)) (3.1.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning==1.9.0->-r requirements.txt (line 8)) (3.11.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair==4.2.2->-r requirements.txt (line 15)) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair==4.2.2->-r requirements.txt (line 15)) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair==4.2.2->-r requirements.txt (line 15)) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair==4.2.2->-r requirements.txt (line 15)) (0.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich==13.7.0->-r requirements.txt (line 40)) (0.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.18->altair==4.2.2->-r requirements.txt (line 15)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.18->altair==4.2.2->-r requirements.txt (line 15)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.18->altair==4.2.2->-r requirements.txt (line 15)) (2024.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.25.0->-r requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.25.0->-r requirements.txt (line 1)) (3.4.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.25.0->-r requirements.txt (line 1)) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->-r requirements.txt (line 12)) (3.0.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers==0.25.0->diffusers[torch]==0.25.0->-r requirements.txt (line 3)) (3.21.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.36.2->-r requirements.txt (line 2)) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.36.2->-r requirements.txt (line 2)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.36.2->-r requirements.txt (line 2)) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.36.2->-r requirements.txt (line 2)) (2024.8.30)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0->-r requirements.txt (line 8)) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0->-r requirements.txt (line 8)) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0->-r requirements.txt (line 8)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0->-r requirements.txt (line 8)) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0->-r requirements.txt (line 8)) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0->-r requirements.txt (line 8)) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0->-r requirements.txt (line 8)) (4.0.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate==0.25.0->-r requirements.txt (line 1)) (1.3.0)\n",
            "Downloading accelerate-0.25.0-py3-none-any.whl (265 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.36.2-py3-none-any.whl (8.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m115.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading diffusers-0.25.0-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m72.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python-4.8.1.78-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-1.9.0-py3-none-any.whl (825 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m825.8/825.8 kB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.43.0-py3-none-manylinux_2_24_x86_64.whl (102.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.2/102.2 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading prodigyopt-1.0-py3-none-any.whl (5.5 kB)\n",
            "Downloading lion_pytorch-0.0.6-py3-none-any.whl (4.2 kB)\n",
            "Downloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading easygui-0.98.3-py2.py3-none-any.whl (92 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.7/92.7 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading voluptuous-0.13.1-py3-none-any.whl (29 kB)\n",
            "Downloading huggingface_hub-0.20.1-py3-none-any.whl (330 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.1/330.1 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rich-13.7.0-py3-none-any.whl (240 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.6/240.6 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m112.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.9-py3-none-any.whl (28 kB)\n",
            "Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m101.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.6.0-py3-none-any.whl (926 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m926.4/926.4 kB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: voluptuous, library, easygui, safetensors, prodigyopt, opencv-python, lightning-utilities, ftfy, einops, tensorboard, rich, huggingface-hub, torchmetrics, tokenizers, lion-pytorch, diffusers, bitsandbytes, accelerate, transformers, pytorch-lightning\n",
            "  Running setup.py develop for library\n",
            "  Attempting uninstall: safetensors\n",
            "    Found existing installation: safetensors 0.4.5\n",
            "    Uninstalling safetensors-0.4.5:\n",
            "      Successfully uninstalled safetensors-0.4.5\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.10.0.84\n",
            "    Uninstalling opencv-python-4.10.0.84:\n",
            "      Successfully uninstalled opencv-python-4.10.0.84\n",
            "  Attempting uninstall: einops\n",
            "    Found existing installation: einops 0.8.0\n",
            "    Uninstalling einops-0.8.0:\n",
            "      Successfully uninstalled einops-0.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.17.1\n",
            "    Uninstalling tensorboard-2.17.1:\n",
            "      Successfully uninstalled tensorboard-2.17.1\n",
            "  Attempting uninstall: rich\n",
            "    Found existing installation: rich 13.9.4\n",
            "    Uninstalling rich-13.9.4:\n",
            "      Successfully uninstalled rich-13.9.4\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.26.2\n",
            "    Uninstalling huggingface-hub-0.26.2:\n",
            "      Successfully uninstalled huggingface-hub-0.26.2\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.20.3\n",
            "    Uninstalling tokenizers-0.20.3:\n",
            "      Successfully uninstalled tokenizers-0.20.3\n",
            "  Attempting uninstall: diffusers\n",
            "    Found existing installation: diffusers 0.31.0\n",
            "    Uninstalling diffusers-0.31.0:\n",
            "      Successfully uninstalled diffusers-0.31.0\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 1.1.1\n",
            "    Uninstalling accelerate-1.1.1:\n",
            "      Successfully uninstalled accelerate-1.1.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.46.2\n",
            "    Uninstalling transformers-4.46.2:\n",
            "      Successfully uninstalled transformers-4.46.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pymc 5.18.2 requires rich>=13.7.1, but you have rich 13.7.0 which is incompatible.\n",
            "sentence-transformers 3.2.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.36.2 which is incompatible.\n",
            "tensorflow 2.17.1 requires tensorboard<2.18,>=2.17, but you have tensorboard 2.18.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-0.25.0 bitsandbytes-0.43.0 diffusers-0.25.0 easygui-0.98.3 einops-0.7.0 ftfy-6.1.1 huggingface-hub-0.20.1 library-0.0.0 lightning-utilities-0.11.9 lion-pytorch-0.0.6 opencv-python-4.8.1.78 prodigyopt-1.0 pytorch-lightning-1.9.0 rich-13.7.0 safetensors-0.4.2 tensorboard-2.18.0 tokenizers-0.15.2 torchmetrics-1.6.0 transformers-4.36.2 voluptuous-0.13.1\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Collecting xformers==0.0.23.post1\n",
            "  Downloading https://download.pytorch.org/whl/cu121/xformers-0.0.23.post1-cp310-cp310-manylinux2014_x86_64.whl (213.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xformers==0.0.23.post1) (1.26.4)\n",
            "Requirement already satisfied: torch==2.1.2 in /usr/local/lib/python3.10/dist-packages (from xformers==0.0.23.post1) (2.1.2+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->xformers==0.0.23.post1) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->xformers==0.0.23.post1) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->xformers==0.0.23.post1) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->xformers==0.0.23.post1) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->xformers==0.0.23.post1) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->xformers==0.0.23.post1) (2024.10.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->xformers==0.0.23.post1) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.2->xformers==0.0.23.post1) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.2->xformers==0.0.23.post1) (1.3.0)\n",
            "Installing collected packages: xformers\n",
            "Successfully installed xformers-0.0.23.post1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qW-6uP3bM12I",
        "outputId": "b98bbc29-ab4a-4d1f-9ce3-3bc16d79d21c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r----------------------------------------------------------------------------------------------------In which compute environment are you running?\n",
            "Please input a choice index (starting from 0), and press enter\n",
            " ➔  \u001b[32mThis machine\u001b[0m\r\n",
            "    AWS (Amazon SageMaker)\n",
            "\u001b[2A\u001b[?25l0\n",
            "\u001b[32mThis machine\u001b[0m\n",
            "----------------------------------------------------------------------------------------------------Which type of machine are you using?\n",
            "Please input a choice index (starting from 0), and press enter\n",
            " ➔  \u001b[32mNo distributed training\u001b[0m\n",
            "    multi-CPU\n",
            "    multi-XPU\n",
            "    multi-GPU\n",
            "    multi-NPU\n",
            "    TPU\n",
            "\u001b[6A\u001b[?25l0\n",
            "\u001b[32mNo distributed training\u001b[0m\n",
            "\u001b[?25hDo you want to run your training on CPU only (even if a GPU / Apple Silicon / Ascend NPU device is available)? [yes/NO]:NO\n",
            "Do you wish to optimize your script with torch dynamo?[yes/NO]:NO\n",
            "Do you want to use DeepSpeed? [yes/NO]: NO\n",
            "What GPU(s) (by id) should be used for training on this machine as a comma-seperated list? [all]:all\n",
            "----------------------------------------------------------------------------------------------------Do you wish to use FP16 or BF16 (mixed precision)?\n",
            "Please input a choice index (starting from 0), and press enter\n",
            " ➔  \u001b[32mno\u001b[0m\n",
            "    fp16\n",
            "    bf16\n",
            "    fp8\n",
            "\u001b[4A\u001b[?25l1\n",
            "\u001b[32mfp16\u001b[0m\n",
            "\u001b[?25haccelerate configuration saved at /root/.cache/huggingface/accelerate/default_config.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate launch --num_cpu_threads_per_process 1 train_network.py --pretrained_model_name_or_path=/content/trains/models/anyloraCheckpoint_bakedvaeBlessedFp16.safetensors --dataset_config=/content/trains/config.toml --output_dir=/content/outputs --output_name=kinkakuji --save_model_as=safetensors --prior_loss_weight=1.0 --max_train_steps=400 --learning_rate=1e-4 --optimizer_type=\"AdamW8bit\" --xformers --mixed_precision=\"fp16\" --cache_latents --gradient_checkpointing --network_module=networks.lora"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxMUFTIDN4Cv",
        "outputId": "f219f20b-ce5f-4f7f-cf1c-ce0e5d8b48bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-25 08:24:33.393675: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-11-25 08:24:33.414809: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-11-25 08:24:33.421287: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-11-25 08:24:34.487722: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[2;36m2024-11-25 08:24:35\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m prepare tokenizer                                    \u001b]8;id=758221;file:///content/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=461244;file:///content/sd-scripts/library/train_util.py#4227\u001b\\\u001b[2m4227\u001b[0m\u001b]8;;\u001b\\\n",
            "tokenizer_config.json: 100% 905/905 [00:00<00:00, 4.34MB/s]\n",
            "vocab.json: 100% 961k/961k [00:00<00:00, 1.09MB/s]\n",
            "merges.txt: 100% 525k/525k [00:00<00:00, 1.11MB/s]\n",
            "special_tokens_map.json: 100% 389/389 [00:00<00:00, 2.43MB/s]\n",
            "tokenizer.json: 100% 2.22M/2.22M [00:01<00:00, 1.40MB/s]\n",
            "\u001b[2;36m2024-11-25 08:24:41\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading dataset config from                        \u001b]8;id=588068;file:///content/sd-scripts/train_network.py\u001b\\\u001b[2mtrain_network.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=505844;file:///content/sd-scripts/train_network.py#161\u001b\\\u001b[2m161\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m                    \u001b[0m         \u001b[35m/content/trains/\u001b[0m\u001b[95mconfig.toml\u001b[0m                        \u001b[2m                    \u001b[0m\n",
            "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m prepare images.                                      \u001b]8;id=504205;file:///content/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=848512;file:///content/sd-scripts/library/train_util.py#1572\u001b\\\u001b[2m1572\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m found directory \u001b[35m/content/trains/dataset/\u001b[0m\u001b[95mData_sight\u001b[0m   \u001b]8;id=366304;file:///content/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=360554;file:///content/sd-scripts/library/train_util.py#1519\u001b\\\u001b[2m1519\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m                    \u001b[0m         contains \u001b[1;36m9\u001b[0m image files                               \u001b[2m                  \u001b[0m\n",
            "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1;36m90\u001b[0m train images with repeating.                      \u001b]8;id=495208;file:///content/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=604200;file:///content/sd-scripts/library/train_util.py#1613\u001b\\\u001b[2m1613\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1;36m0\u001b[0m reg images.                                        \u001b]8;id=246067;file:///content/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=868394;file:///content/sd-scripts/library/train_util.py#1616\u001b\\\u001b[2m1616\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m no regularization images \u001b[35m/\u001b[0m                           \u001b]8;id=778797;file:///content/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=954908;file:///content/sd-scripts/library/train_util.py#1621\u001b\\\u001b[2m1621\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m                    \u001b[0m         正則化画像が見つかりませんでした                     \u001b[2m                  \u001b[0m\n",
            "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0mDataset \u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m                                          \u001b]8;id=49355;file:///content/sd-scripts/library/config_util.py\u001b\\\u001b[2mconfig_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=655470;file:///content/sd-scripts/library/config_util.py#565\u001b\\\u001b[2m565\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m                    \u001b[0m           batch_size: \u001b[1;36m4\u001b[0m                                      \u001b[2m                  \u001b[0m\n",
            "\u001b[2;36m                    \u001b[0m           resolution: \u001b[1m(\u001b[0m\u001b[1;36m512\u001b[0m, \u001b[1;36m512\u001b[0m\u001b[1m)\u001b[0m                             \u001b[2m                  \u001b[0m\n",
            "\u001b[2;36m                    \u001b[0m           enable_bucket: \u001b[3;92mTrue\u001b[0m                                \u001b[2m                  \u001b[0m\n",
            "\u001b[2;36m                    \u001b[0m           network_multiplier: \u001b[1;36m1.0\u001b[0m                            \u001b[2m                  \u001b[0m\n",
            "\u001b[2;36m                    \u001b[0m           min_bucket_reso: \u001b[1;36m256\u001b[0m                               \u001b[2m                  \u001b[0m\n",
            "\u001b[2;36m                    \u001b[0m           max_bucket_reso: \u001b[1;36m1024\u001b[0m                              \u001b[2m                  \u001b[0m\n",
            "\u001b[2;36m                    \u001b[0m           bucket_reso_steps: \u001b[1;36m64\u001b[0m                              \u001b[2m                  \u001b[0m\n",
            "\u001b[2;36m                    \u001b[0m           bucket_no_upscale: \u001b[3;91mFalse\u001b[0m                           \u001b[2m                  \u001b[0m\n",
            "\u001b[2;36m                    \u001b[0m                                                              \u001b[2m                  \u001b[0m\n",
            "\u001b[2;36m                    \u001b[0m           \u001b[1m[\u001b[0mSubset \u001b[1;36m0\u001b[0m of Dataset \u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m                            \u001b[2m                  \u001b[0m\n",
            "\u001b[2;36m                    \u001b[0m             image_dir: \u001b[32m\"/content/trains/dataset/Data_sight\"\u001b[0m  \u001b[2m                  \u001b[0m\n",
            "\u001b[2;36m                    \u001b[0m             image_count: \u001b[1;36m9\u001b[0m                                   \u001b[2m                  \u001b[0m\n",
            "\u001b[2;36m                    \u001b[0m             num_repeats: \u001b[1;36m10\u001b[0m                                  \u001b[2m                  \u001b[0m\n",
            "\u001b[2;36m                    \u001b[0m             shuffle_caption: \u001b[3;91mFalse\u001b[0m                           \u001b[2m                  \u001b[0m\n",
            "\u001b[2;36m                    \u001b[0m             keep_tokens: \u001b[1;36m0\u001b[0m                                   \u001b[2m                  \u001b[0m\n",
            "\u001b[2;36m                    \u001b[0m             keep_tokens_separator:                           \u001b[2m                  \u001b[0m\n",
            "\u001b[2;36m                    \u001b[0m             secondary_separator: \u001b[3;35mNone\u001b[0m                        \u001b[2m                  \u001b[0m\n",
            "\u001b[2;36m                    \u001b[0m             enable_wildcard: \u001b[3;91mFalse\u001b[0m                           \u001b[2m                  \u001b[0m\n",
            "\u001b[2;36m                    \u001b[0m             caption_dropout_rate: \u001b[1;36m0.0\u001b[0m                        \u001b[2m                  \u001b[0m\n",
            "\u001b[2;36m                    \u001b[0m             caption_dropout_every_n_epoches: \u001b[1;36m0\u001b[0m               \u001b[2m                  \u001b[0m\n",
            "\u001b[2;36m                    \u001b[0m             caption_tag_dropout_rate: \u001b[1;36m0.0\u001b[0m                    \u001b[2m                  \u001b[0m\n",
            "\u001b[2;36m                    \u001b[0m             caption_prefix: \u001b[3;35mNone\u001b[0m                             \u001b[2m                  \u001b[0m\n",
            "\u001b[2;36m                    \u001b[0m             caption_suffix: \u001b[3;35mNone\u001b[0m                             \u001b[2m                  \u001b[0m\n",
            "\u001b[2;36m                    \u001b[0m             color_aug: \u001b[3;91mFalse\u001b[0m                                 \u001b[2m                  \u001b[0m\n",
            "\u001b[2;36m                    \u001b[0m             flip_aug: \u001b[3;91mFalse\u001b[0m                                  \u001b[2m                  \u001b[0m\n",
            "\u001b[2;36m                    \u001b[0m             face_crop_aug_range: \u001b[3;35mNone\u001b[0m                        \u001b[2m                  \u001b[0m\n",
            "\u001b[2;36m                    \u001b[0m             random_crop: \u001b[3;91mFalse\u001b[0m                               \u001b[2m                  \u001b[0m\n",
            "\u001b[2;36m                    \u001b[0m             token_warmup_min: \u001b[1;36m1\u001b[0m,                             \u001b[2m                  \u001b[0m\n",
            "\u001b[2;36m                    \u001b[0m             token_warmup_step: \u001b[1;36m0\u001b[0m,                            \u001b[2m                  \u001b[0m\n",
            "\u001b[2;36m                    \u001b[0m             is_reg: \u001b[3;91mFalse\u001b[0m                                    \u001b[2m                  \u001b[0m\n",
            "\u001b[2;36m                    \u001b[0m             class_tokens: \u001b[3;35mNone\u001b[0m                               \u001b[2m                  \u001b[0m\n",
            "\u001b[2;36m                    \u001b[0m             caption_extension: .txt                          \u001b[2m                  \u001b[0m\n",
            "\u001b[2;36m                    \u001b[0m                                                              \u001b[2m                  \u001b[0m\n",
            "\u001b[2;36m                    \u001b[0m                                                              \u001b[2m                  \u001b[0m\n",
            "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0mDataset \u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m                                          \u001b]8;id=650421;file:///content/sd-scripts/library/config_util.py\u001b\\\u001b[2mconfig_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=497282;file:///content/sd-scripts/library/config_util.py#571\u001b\\\u001b[2m571\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m loading image sizes.                                  \u001b]8;id=344973;file:///content/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=103343;file:///content/sd-scripts/library/train_util.py#853\u001b\\\u001b[2m853\u001b[0m\u001b]8;;\u001b\\\n",
            "100% 9/9 [00:00<00:00, 184.83it/s]\n",
            "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m make buckets                                          \u001b]8;id=410250;file:///content/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=527095;file:///content/sd-scripts/library/train_util.py#859\u001b\\\u001b[2m859\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m number of images \u001b[1m(\u001b[0mincluding repeats\u001b[1m)\u001b[0m \u001b[35m/\u001b[0m                \u001b]8;id=875072;file:///content/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=194993;file:///content/sd-scripts/library/train_util.py#905\u001b\\\u001b[2m905\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m                    \u001b[0m         各bucketの画像枚数（繰り返し回数を含む）              \u001b[2m                 \u001b[0m\n",
            "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m bucket \u001b[1;36m0\u001b[0m: resolution \u001b[1m(\u001b[0m\u001b[1;36m576\u001b[0m, \u001b[1;36m448\u001b[0m\u001b[1m)\u001b[0m, count: \u001b[1;36m40\u001b[0m            \u001b]8;id=444950;file:///content/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=41178;file:///content/sd-scripts/library/train_util.py#910\u001b\\\u001b[2m910\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m bucket \u001b[1;36m1\u001b[0m: resolution \u001b[1m(\u001b[0m\u001b[1;36m640\u001b[0m, \u001b[1;36m384\u001b[0m\u001b[1m)\u001b[0m, count: \u001b[1;36m50\u001b[0m            \u001b]8;id=872017;file:///content/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=497184;file:///content/sd-scripts/library/train_util.py#910\u001b\\\u001b[2m910\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m mean ar error \u001b[1m(\u001b[0mwithout repeats\u001b[1m)\u001b[0m: \u001b[1;36m0.10128021722726555\u001b[0m  \u001b]8;id=42022;file:///content/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=755814;file:///content/sd-scripts/library/train_util.py#915\u001b\\\u001b[2m915\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m preparing accelerator                              \u001b]8;id=961482;file:///content/sd-scripts/train_network.py\u001b\\\u001b[2mtrain_network.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=831861;file:///content/sd-scripts/train_network.py#225\u001b\\\u001b[2m225\u001b[0m\u001b]8;;\u001b\\\n",
            "accelerator device: cuda\n",
            "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m loading model for process \u001b[1;36m0\u001b[0m/\u001b[1;36m1\u001b[0m                        \u001b]8;id=510073;file:///content/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=615592;file:///content/sd-scripts/library/train_util.py#4385\u001b\\\u001b[2m4385\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m load StableDiffusion checkpoint:                     \u001b]8;id=16996;file:///content/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=767022;file:///content/sd-scripts/library/train_util.py#4341\u001b\\\u001b[2m4341\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m                    \u001b[0m         \u001b[35m/content/trains/models/\u001b[0m\u001b[95manyloraCheckpoint_bakedvaeBle\u001b[0m \u001b[2m                  \u001b[0m\n",
            "\u001b[2;36m                    \u001b[0m         \u001b[95mssedFp16.safetensors\u001b[0m                                 \u001b[2m                  \u001b[0m\n",
            "\u001b[2;36m2024-11-25 08:24:42\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m UNet2DConditionModel: \u001b[1;36m64\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m768\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m    \u001b]8;id=178763;file:///content/sd-scripts/library/original_unet.py\u001b\\\u001b[2moriginal_unet.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=348689;file:///content/sd-scripts/library/original_unet.py#1387\u001b\\\u001b[2m1387\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m2024-11-25 08:24:51\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m loading u-net: \u001b[1m<\u001b[0m\u001b[1;95mAll\u001b[0m\u001b[39m keys matched successfully\u001b[0m\u001b[1m>\u001b[0m       \u001b]8;id=896870;file:///content/sd-scripts/library/model_util.py\u001b\\\u001b[2mmodel_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=731560;file:///content/sd-scripts/library/model_util.py#1009\u001b\\\u001b[2m1009\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m2024-11-25 08:24:52\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m loading vae: \u001b[1m<\u001b[0m\u001b[1;95mAll\u001b[0m\u001b[39m keys matched successfully\u001b[0m\u001b[1m>\u001b[0m         \u001b]8;id=954220;file:///content/sd-scripts/library/model_util.py\u001b\\\u001b[2mmodel_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=982012;file:///content/sd-scripts/library/model_util.py#1017\u001b\\\u001b[2m1017\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m2024-11-25 08:24:54\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m loading text encoder: \u001b[1m<\u001b[0m\u001b[1;95mAll\u001b[0m\u001b[39m keys matched \u001b[0m             \u001b]8;id=130488;file:///content/sd-scripts/library/model_util.py\u001b\\\u001b[2mmodel_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=665845;file:///content/sd-scripts/library/model_util.py#1074\u001b\\\u001b[2m1074\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m                    \u001b[0m         \u001b[39msuccessfully\u001b[0m\u001b[1m>\u001b[0m                                        \u001b[2m                  \u001b[0m\n",
            "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Enable xformers for U-Net                            \u001b]8;id=410212;file:///content/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=95978;file:///content/sd-scripts/library/train_util.py#2660\u001b\\\u001b[2m2660\u001b[0m\u001b]8;;\u001b\\\n",
            "import network module: networks.lora\n",
            "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0mDataset \u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m                                          \u001b]8;id=22687;file:///content/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=204043;file:///content/sd-scripts/library/train_util.py#2079\u001b\\\u001b[2m2079\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m caching latents.                                      \u001b]8;id=762477;file:///content/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=839643;file:///content/sd-scripts/library/train_util.py#974\u001b\\\u001b[2m974\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m checking cache validity\u001b[33m...\u001b[0m                            \u001b]8;id=446293;file:///content/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=650746;file:///content/sd-scripts/library/train_util.py#984\u001b\\\u001b[2m984\u001b[0m\u001b]8;;\u001b\\\n",
            "100% 9/9 [00:00<00:00, 227402.02it/s]\n",
            "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m caching latents\u001b[33m...\u001b[0m                                   \u001b]8;id=75467;file:///content/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=678350;file:///content/sd-scripts/library/train_util.py#1021\u001b\\\u001b[2m1021\u001b[0m\u001b]8;;\u001b\\\n",
            "100% 9/9 [00:02<00:00,  3.05it/s]\n",
            "\u001b[2;36m2024-11-25 08:24:58\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m create LoRA network. base dim \u001b[1m(\u001b[0mrank\u001b[1m)\u001b[0m: \u001b[1;36m4\u001b[0m, alpha: \u001b[1;36m1\u001b[0m           \u001b]8;id=489822;file:///content/sd-scripts/networks/lora.py\u001b\\\u001b[2mlora.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=41291;file:///content/sd-scripts/networks/lora.py#810\u001b\\\u001b[2m810\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m neuron dropout: \u001b[33mp\u001b[0m=\u001b[3;35mNone\u001b[0m, rank dropout: \u001b[33mp\u001b[0m=\u001b[3;35mNone\u001b[0m, module        \u001b]8;id=272769;file:///content/sd-scripts/networks/lora.py\u001b\\\u001b[2mlora.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=375972;file:///content/sd-scripts/networks/lora.py#811\u001b\\\u001b[2m811\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m                    \u001b[0m         dropout: \u001b[33mp\u001b[0m=\u001b[3;35mNone\u001b[0m                                             \u001b[2m           \u001b[0m\n",
            "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m create LoRA for Text Encoder:                               \u001b]8;id=963098;file:///content/sd-scripts/networks/lora.py\u001b\\\u001b[2mlora.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=597445;file:///content/sd-scripts/networks/lora.py#905\u001b\\\u001b[2m905\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m create LoRA for Text Encoder: \u001b[1;36m72\u001b[0m modules.                   \u001b]8;id=60870;file:///content/sd-scripts/networks/lora.py\u001b\\\u001b[2mlora.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=826957;file:///content/sd-scripts/networks/lora.py#910\u001b\\\u001b[2m910\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m create LoRA for U-Net: \u001b[1;36m192\u001b[0m modules.                         \u001b]8;id=555193;file:///content/sd-scripts/networks/lora.py\u001b\\\u001b[2mlora.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=262864;file:///content/sd-scripts/networks/lora.py#918\u001b\\\u001b[2m918\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m enable LoRA for text encoder                                \u001b]8;id=183311;file:///content/sd-scripts/networks/lora.py\u001b\\\u001b[2mlora.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=13845;file:///content/sd-scripts/networks/lora.py#961\u001b\\\u001b[2m961\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m enable LoRA for U-Net                                       \u001b]8;id=917299;file:///content/sd-scripts/networks/lora.py\u001b\\\u001b[2mlora.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=533305;file:///content/sd-scripts/networks/lora.py#966\u001b\\\u001b[2m966\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m CrossAttnDownBlock2D \u001b[3;91mFalse\u001b[0m -> \u001b[3;92mTrue\u001b[0m                \u001b]8;id=878351;file:///content/sd-scripts/library/original_unet.py\u001b\\\u001b[2moriginal_unet.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=689560;file:///content/sd-scripts/library/original_unet.py#1521\u001b\\\u001b[2m1521\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m CrossAttnDownBlock2D \u001b[3;91mFalse\u001b[0m -> \u001b[3;92mTrue\u001b[0m                \u001b]8;id=13040;file:///content/sd-scripts/library/original_unet.py\u001b\\\u001b[2moriginal_unet.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=480199;file:///content/sd-scripts/library/original_unet.py#1521\u001b\\\u001b[2m1521\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m CrossAttnDownBlock2D \u001b[3;91mFalse\u001b[0m -> \u001b[3;92mTrue\u001b[0m                \u001b]8;id=47916;file:///content/sd-scripts/library/original_unet.py\u001b\\\u001b[2moriginal_unet.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=570760;file:///content/sd-scripts/library/original_unet.py#1521\u001b\\\u001b[2m1521\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m DownBlock2D \u001b[3;91mFalse\u001b[0m -> \u001b[3;92mTrue\u001b[0m                         \u001b]8;id=999428;file:///content/sd-scripts/library/original_unet.py\u001b\\\u001b[2moriginal_unet.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=505232;file:///content/sd-scripts/library/original_unet.py#1521\u001b\\\u001b[2m1521\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m UNetMidBlock2DCrossAttn \u001b[3;91mFalse\u001b[0m -> \u001b[3;92mTrue\u001b[0m             \u001b]8;id=376649;file:///content/sd-scripts/library/original_unet.py\u001b\\\u001b[2moriginal_unet.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=618951;file:///content/sd-scripts/library/original_unet.py#1521\u001b\\\u001b[2m1521\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m UpBlock2D \u001b[3;91mFalse\u001b[0m -> \u001b[3;92mTrue\u001b[0m                           \u001b]8;id=651246;file:///content/sd-scripts/library/original_unet.py\u001b\\\u001b[2moriginal_unet.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=138773;file:///content/sd-scripts/library/original_unet.py#1521\u001b\\\u001b[2m1521\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m CrossAttnUpBlock2D \u001b[3;91mFalse\u001b[0m -> \u001b[3;92mTrue\u001b[0m                  \u001b]8;id=434548;file:///content/sd-scripts/library/original_unet.py\u001b\\\u001b[2moriginal_unet.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=869167;file:///content/sd-scripts/library/original_unet.py#1521\u001b\\\u001b[2m1521\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m CrossAttnUpBlock2D \u001b[3;91mFalse\u001b[0m -> \u001b[3;92mTrue\u001b[0m                  \u001b]8;id=201651;file:///content/sd-scripts/library/original_unet.py\u001b\\\u001b[2moriginal_unet.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=732517;file:///content/sd-scripts/library/original_unet.py#1521\u001b\\\u001b[2m1521\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m CrossAttnUpBlock2D \u001b[3;91mFalse\u001b[0m -> \u001b[3;92mTrue\u001b[0m                  \u001b]8;id=668361;file:///content/sd-scripts/library/original_unet.py\u001b\\\u001b[2moriginal_unet.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=469903;file:///content/sd-scripts/library/original_unet.py#1521\u001b\\\u001b[2m1521\u001b[0m\u001b]8;;\u001b\\\n",
            "prepare optimizer, data loader etc.\n",
            "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m use \u001b[1;36m8\u001b[0m-bit AdamW optimizer | \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m                       \u001b]8;id=917019;file:///content/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=434536;file:///content/sd-scripts/library/train_util.py#3889\u001b\\\u001b[2m3889\u001b[0m\u001b]8;;\u001b\\\n",
            "running training / 学習開始\n",
            "  num train images * repeats / 学習画像の数×繰り返し回数: 90\n",
            "  num reg images / 正則化画像の数: 0\n",
            "  num batches per epoch / 1epochのバッチ数: 23\n",
            "  num epochs / epoch数: 18\n",
            "  batch size per device / バッチサイズ: 4\n",
            "  gradient accumulation steps / 勾配を合計するステップ数 = 1\n",
            "  total optimization steps / 学習ステップ数: 400\n",
            "steps:   0% 0/400 [00:00<?, ?it/s]\n",
            "epoch 1/18\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "steps:   6% 23/400 [00:18<04:56,  1.27it/s, avr_loss=0.166]\n",
            "epoch 2/18\n",
            "steps:  12% 46/400 [00:33<04:19,  1.36it/s, avr_loss=0.108]\n",
            "epoch 3/18\n",
            "steps:  17% 69/400 [00:49<03:58,  1.39it/s, avr_loss=0.143]\n",
            "epoch 4/18\n",
            "steps:  23% 92/400 [01:06<03:41,  1.39it/s, avr_loss=0.164]\n",
            "epoch 5/18\n",
            "steps:  29% 115/400 [01:22<03:23,  1.40it/s, avr_loss=0.119]\n",
            "epoch 6/18\n",
            "steps:  34% 138/400 [01:38<03:06,  1.40it/s, avr_loss=0.142]\n",
            "epoch 7/18\n",
            "steps:  40% 161/400 [01:54<02:49,  1.41it/s, avr_loss=0.192]\n",
            "epoch 8/18\n",
            "steps:  46% 184/400 [02:10<02:32,  1.41it/s, avr_loss=0.168]\n",
            "epoch 9/18\n",
            "steps:  52% 207/400 [02:26<02:16,  1.41it/s, avr_loss=0.141]\n",
            "epoch 10/18\n",
            "steps:  57% 230/400 [02:42<02:00,  1.42it/s, avr_loss=0.129]\n",
            "epoch 11/18\n",
            "steps:  63% 253/400 [02:58<01:43,  1.42it/s, avr_loss=0.133]\n",
            "epoch 12/18\n",
            "steps:  69% 276/400 [03:14<01:27,  1.42it/s, avr_loss=0.158]\n",
            "epoch 13/18\n",
            "steps:  75% 299/400 [03:31<01:11,  1.41it/s, avr_loss=0.128]\n",
            "epoch 14/18\n",
            "steps:  80% 322/400 [03:47<00:55,  1.41it/s, avr_loss=0.148]\n",
            "epoch 15/18\n",
            "steps:  86% 345/400 [04:03<00:38,  1.42it/s, avr_loss=0.122]\n",
            "epoch 16/18\n",
            "steps:  92% 368/400 [04:19<00:22,  1.42it/s, avr_loss=0.122]\n",
            "epoch 17/18\n",
            "steps:  98% 391/400 [04:36<00:06,  1.42it/s, avr_loss=0.11]\n",
            "epoch 18/18\n",
            "steps: 100% 400/400 [04:42<00:00,  1.41it/s, avr_loss=0.0963]\n",
            "saving checkpoint: /content/outputs/fujisan.safetensors\n",
            "\u001b[2;36m2024-11-25 08:29:53\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m model saved.                                       \u001b]8;id=438542;file:///content/sd-scripts/train_network.py\u001b\\\u001b[2mtrain_network.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=809695;file:///content/sd-scripts/train_network.py#999\u001b\\\u001b[2m999\u001b[0m\u001b]8;;\u001b\\\n",
            "steps: 100% 400/400 [04:43<00:00,  1.41it/s, avr_loss=0.0963]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Haao16BNTTIX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hcZIZ6aOSCfQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0lN52yuBR9-3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}